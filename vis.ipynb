{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def valid_result(key, accuracy):\n",
    "    if key.dataset == 'CIFAR10':\n",
    "        threshold = 0.4\n",
    "    elif key.dataset == 'MNIST':\n",
    "        threshold = 0.975\n",
    "    else:\n",
    "        return False\n",
    "    if accuracy < threshold:\n",
    "        return False\n",
    "    if key.epsilon == 0 and key.temperature != 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def iterate_results(resutls_dir=Path.home() / 'results'):\n",
    "    Key = namedtuple('Key', (\n",
    "        'dataset', 'model', 'epsilon',\n",
    "        'learning_rate', 'factor', 'temperature'))\n",
    "    for p in Path(resutls_dir).iterdir():\n",
    "        if len(p.name.split('-')) != 3:\n",
    "            continue\n",
    "        d, m, e = p.name.split('-')\n",
    "        for p in p.iterdir():\n",
    "            if len(p.name.split('-')) != 3:\n",
    "                continue\n",
    "            l, f, t = p.name.split('-')\n",
    "            key = Key(d, m, float(e), float(l), float(f), int(t))\n",
    "            p = p / 'checkpoint.pth'\n",
    "            if not p.exists():\n",
    "                continue\n",
    "            yield key, p\n",
    "\n",
    "\n",
    "def iterate_models(results_iterator=iterate_results, check=valid_result):\n",
    "    Experiment = namedtuple('Experiment', (\n",
    "        'method', 'dataset', 'model', 'epsilon'))\n",
    "    Result = namedtuple('Result', ('state_dict', 'accuracy', 'pgd'))\n",
    "    for k, p in results_iterator():\n",
    "        if k.epsilon == 0:\n",
    "            e = 'nominal'\n",
    "        elif k.learning_rate == 0:\n",
    "            e = 'deepmind'\n",
    "        else:\n",
    "            e = 'ours'\n",
    "        e = Experiment(e, k.dataset, k.model, k.epsilon)\n",
    "        c = torch.load(p, 'cpu')\n",
    "        accuracy = c.get('accuracy', c.get('best_acc1', 0) / 100)\n",
    "        if check is not None and not check(k, accuracy):\n",
    "            continue\n",
    "        robustness = [1 - torch.load(g, 'cpu')['fooling_rate']\n",
    "                      for g in p.parent.glob('pgd*.pth')]\n",
    "        if len(robustness) == 0:\n",
    "            print(f'No PGD in: {p.parent}')\n",
    "            continue\n",
    "        pgd = sum(robustness) / (len(robustness) + 1)\n",
    "        r = Result(c['state_dict'], accuracy, pgd)\n",
    "        yield e, r\n",
    "\n",
    "\n",
    "def get_results(model_iterator=iterate_models):\n",
    "    results = {}\n",
    "    for k, r in model_iterator():\n",
    "        if k not in results or results[k].pgd < r.pgd:\n",
    "            results[k] = r\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results()\n",
    "k, v = next(iter(results.items()))\n",
    "torch.save({\n",
    "    'keys': k._fields,\n",
    "    'values': v._fields,\n",
    "    'experiments': {tuple(k): tuple(v) for k, v in results.items()},\n",
    "}, 'results.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibp-neurips19",
   "language": "python",
   "name": "ibp-neurips19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
